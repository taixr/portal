<!doctype html>
<html lang="zh" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-generative-ai/transformers" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">第二章 Transformers | Taixr</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:image" content="https://i.taixr.com/logo.jpeg"><meta data-rh="true" name="twitter:image" content="https://i.taixr.com/logo.jpeg"><meta data-rh="true" property="og:url" content="https://www.taixr.com/docs/generative-ai/transformers"><meta data-rh="true" property="og:locale" content="zh"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh"><meta data-rh="true" name="docsearch:language" content="zh"><meta data-rh="true" name="keywords" content="ai, 人工智能, AR, VR, XR, MR, 增强现实，虚拟现实, 混合现实, visionOS, Vision Pro"><meta data-rh="true" name="twitter:card" content="https://i.taixr.com/logo.jpeg"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="第二章 Transformers | Taixr"><meta data-rh="true" name="description" content="很多人将最近一波生成式人工智能的进展追溯到2017年发布称为transformer的模型。其最著名的应用是强大的大语言模型（LLM），如Llama和GPT-4，每天有数亿人使用。transformer已成为现代人工智能应用的核心，推动着聊天机器人、搜索系统乃至机器翻译和内容摘要等各类应用。甚至已超越了文本领域，在计算机视觉、音乐生成和蛋白质折叠等领域引起了巨大反响。本章中，我们将探讨transformer背后的核心概念及其工作原理，重点介绍其中一个最常见的应用：语言模型。"><meta data-rh="true" property="og:description" content="很多人将最近一波生成式人工智能的进展追溯到2017年发布称为transformer的模型。其最著名的应用是强大的大语言模型（LLM），如Llama和GPT-4，每天有数亿人使用。transformer已成为现代人工智能应用的核心，推动着聊天机器人、搜索系统乃至机器翻译和内容摘要等各类应用。甚至已超越了文本领域，在计算机视觉、音乐生成和蛋白质折叠等领域引起了巨大反响。本章中，我们将探讨transformer背后的核心概念及其工作原理，重点介绍其中一个最常见的应用：语言模型。"><link data-rh="true" rel="icon" href="https://i.taixr.com/logo.jpeg"><link data-rh="true" rel="canonical" href="https://www.taixr.com/docs/generative-ai/transformers"><link data-rh="true" rel="alternate" href="https://www.taixr.com/docs/generative-ai/transformers" hreflang="zh"><link data-rh="true" rel="alternate" href="https://www.taixr.com/en/docs/generative-ai/transformers" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.taixr.com/docs/generative-ai/transformers" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://PEDULFQVAW-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Taixr RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Taixr Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-K4CD0WFGFG"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K4CD0WFGFG",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Taixr" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.4f939f39.css">
<script src="/assets/js/runtime~main.00cf0026.js" defer="defer"></script>
<script src="/assets/js/main.1e8db02e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="https://i.taixr.com/logo.jpeg" alt="Taixr, all about AI &amp; AR" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="https://i.taixr.com/logo.jpeg" alt="Taixr, all about AI &amp; AR" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Taixr</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/category/generative-ai">Tutorial</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/taixr" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/category/generative-ai">Generative AI</a><button aria-label="折叠侧边栏分类 &#x27;Generative AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/generative-ai/intro">第一章 多媒体生成入门</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/generative-ai/transformers">第二章 Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/generative-ai/diffusion-models">第三章 扩散模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/generative-ai/stable-diffusion">第四章 Stable Diffusion</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/learn-javascript-with-p5js">Learn JavaScript with p5.js</a><button aria-label="展开侧边栏分类 &#x27;Learn JavaScript with p5.js&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/python-scripting">Python Scripting</a><button aria-label="展开侧边栏分类 &#x27;Python Scripting&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/generative-ai"><span itemprop="name">Generative AI</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">第二章 Transformers</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>第二章 Transformers</h1>
<p>很多人将最近一波生成式人工智能的进展追溯到2017年发布称为transformer的模型。其最著名的应用是强大的大语言模型（LLM），如Llama和GPT-4，每天有数亿人使用。transformer已成为现代人工智能应用的核心，推动着聊天机器人、搜索系统乃至机器翻译和内容摘要等各类应用。甚至已超越了文本领域，在计算机视觉、音乐生成和蛋白质折叠等领域引起了巨大反响。本章中，我们将探讨transformer背后的核心概念及其工作原理，重点介绍其中一个最常见的应用：语言模型。</p>
<p>在深入了解transformer之前，我们先退一步，了解什么是语言模型。语言模型（LM）的核心是一个概率模型，它通过前面或周边的词来预测序列中的下一个词（或标记）。这样，它捕获到了语言的基本结构和模式，使其能够生成真实且连贯的文本。例如，给定句子“<code>I began my day eating</code>”，语言模型可能会以高概率预测下一个词为“<code>breakfast</code>”。</p>
<p>那么，transformer在这一过程中发挥什么作用呢？与使用固定大小滑动窗口或循环神经网络（RNN）的传统语言模型不同，transformer设计用于更高  效、更有表现力地处理长距离依赖关系和复杂的词间关系。例如，假设您想使用语言模型总结一篇新闻文章，这篇文章可能包含数百甚至几千个词。传统的语言模型在处理长上下文时会遇到困难，因此摘要可能会遗漏文章开头的一些重要细节。而基于transformer的语言模型在这一任务上表现出色。除了高质量的生成能力外，transformer还具有其他特性，如训练的高效并行化、可扩展性和知识迁移，使其在多种任务中广受欢迎并且非常适用。这一创新的核心是自注意力机制，它使模型能够在整个序列的上下文中权衡每个词的重要性。</p>
<p>为建立对语言模型如何运作的直观理解，我们将使用与现有模型交互的代码示例，并在出现相关部分时进行描述。一起开干吧。</p>
<blockquote>
<p><strong>注</strong>：在英文材料中经常可以看到tranformer和transformers的表述，前者表示以自注意力机制为底层的技术，而transformers可能是指基于这一技术的各类模型，也有可能是指Hugging Face的<a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">transformers</a>库，这个名称在营销角度非常巧妙，但也经常会让人产生误解。</p>
</blockquote>
<p>本文相关代码请见<a href="https://github.com/alanhou/ai/blob/master/hands-on-generative-ai/02-transformers.ipynb" target="_blank" rel="noopener noreferrer">GitHub仓库</a>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="实操语言模型">实操语言模型<a href="#实操语言模型" class="hash-link" aria-label="实操语言模型的直接链接" title="实操语言模型的直接链接">​</a></h2>
<p>在本节中，我们会加载并与现存的（预训练的）transformer模型进行互动，以获得对其工作原理的高阶理解。我们将使用2019年因文本生成能力而引发关注的GPT-2模型。尽管按今天的标准来看，GPT-2  显得小而简单，但它仍然是展示这些语言模型如何运作的好例子。同样的原理也适用于自那以后发布的更大（大100多倍！）且更强的模型。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="文本分词">文本分词<a href="#文本分词" class="hash-link" aria-label="文本分词的直接链接" title="文本分词的直接链接">​</a></h3>
<p>下面开始生成基于初始输入的一些文本。例如，给定短语“<code>it was a dark and stormy</code>”，我们希望模型生成一些词来完善这个句子。模型不能直接接收文本作为输入；其输入必须是以数字表示的数据。为将文本输入到模型中，我们必须首先找到一种将文本序列转换为数字的方法。这个过程称为分词/标记化（tokenization），是所有自然语言处理（NLP）流程中的关键步骤。</p>
<p>一种简单的方法是将文本分割成单个字符，并为每个字符分配一个唯一的数字ID。这个方案对于像中文这样每个字符都包含大量信息的语言可能有用。在像英语这样的语言中，这会创建一个非常小的分词表，并且在运行推理时会有很少的未知标记（训练期间未发现的字符）。然而，这种方法需要许多标记来表示一个字符串，这对性能不利，并且会抹去文本的一些结构和含义——这对准确性是不利的。每个字符携带的信息非常少，使得模型难以学习文本的基本结构。</p>
<p>另一种方法是将文本按单词分割。虽然这可以让每个标记捕捉更多的含义，但它也有缺点：我们需要处理更多的未知词（例如，拼写错误、俚语等），需要处理相同词的不同形式（例如，“run”，“runs”，“running”等），并且我们可能会得到一个非常大的词表，对于像英语这样的语言来说，这个词表可轻松超过五十万个单词。现代的分词策略在这两个极端之间找到了平衡，将文本分割成既能捕获文本结构和含义又能处理未知词和相同词不同形式的词元。</p>
<p>通常同时出现的字符（如最常见的单词）可以分配一个代表整个单词或词组的单个标记。长或复杂的单词，以及有许多词形变化的单词，可能会被分割成多个标记，每个标记通常代表单词的一个有含义部分。没有什么“最佳”分词器；每个语言模型都有其自己的分词器。分词器之间的差异在于支持的标记数量和分词策略。</p>
<p>我们来看GPT-2的分词器如何处理一个句子。首先加载与GPT-2对应的分词器。然后，我们将输入文本（也称为提示词）通过分词器运行，将字符串编码为表示标记的数字。我们使用<code>decode()</code>方法将每个ID转换回其对应的标记，以便进行演示。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids = tokenizer(&quot;It was a dark and stormy&quot;, return_tensors=&quot;pt&quot;).input_ids</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">tensor([[1026,  373,  257, 3223,  290, 6388,   88]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">for t in input_ids[0]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(t, &quot;\t:&quot;, tokenizer.decode(t))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">tensor(1026)    : It</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(373)     :  was</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(257)     :  a</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(3223)    :  dark</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(290)     :  and</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(6388)    :  storm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensor(88)  : y</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>可以看到，分词器将输入字符串分割成一系列标记，并为每个标记分配一个唯一的ID。大多数单词由单个标记表示，但“<code>stormy</code>”被表示为两个标记：一个是“<code> storm</code>”（包括单词前的空格），另一个是后缀“<code>y</code>”。这使得模型能够学习“<code>stormy</code>”与“<code>storm</code>”有关，后缀“<code>y</code>”通常用于将名词变成形容词。GPT-2的词表大约50,000个标记，分词器可以高效地表示几乎所有输入文本，平均每个单词大约1.3个标记。</p>
<blockquote>
<p><strong>注：</strong> 尽管我们经常谈论训练分词器，它与训练模型没有关系。模型训练本质上是随机的（非确定性的），而训练分词器使用的是统计过程，识别出哪些子词在给定数据集中是最合适的选择。如何选择子词是分词算法的设计决策。因此，标记化训练是确定性的。我们不会深入探讨不同的分词策略，但一些最流行的分词方法包括在GPT-2中使用的字节级BPE、WordPiece和SentencePiece。</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="预测概率">预测概率<a href="#预测概率" class="hash-link" aria-label="预测概率的直接链接" title="预测概率的直接链接">​</a></h3>
<p>GPT-2按因果语言模型（也称为自回归模型）训练，这表示它被训练用来在给定前面的标记后预测序列中的下一个标记。transformers库提供了高级工具，让我们能够快速使用这样的模型生成文本或执行其他任务。通过直接检查语言建模任务中的预测，可以帮助我们理解模型如何做出预测。首先来加载模型。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import AutoModelForCausalLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gpt2 = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>注</strong>：请注意<code>AutoTokenizer</code>和<code>AutoModelForCausalLM</code>的使用。transformers库支持几百个模型及相应的分词器。为避免记住每个分词器和模型类的名称，我们使用<code>AutoTokenizer</code>和<code>AutoModelFor</code>。</p>
<p>对于自动模型，我们需要指定使用模型的任务，例如分类（<code>AutoModelForSequenceClassification</code>）或目标检测（<code>AutoModelForObjectDetection</code>）。对于GPT-2，我们将使用与因果语言建模任务相对应的类。使用自动类时，transformers会根据模型的配置选择适用的默认类。例如，其背后使用<code>GPT2Tokenizer</code>和<code>GPT2LMHeadModel</code>。</p>
</blockquote>
<p>如果我们将上一节中的分词/词法单元句子输入模型，会得到每个输入字符串标记对应的50,257个值的结果：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">outputs = gpt2(input_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs.logits.shape  # An output for each input token</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">torch.Size([1, 7, 50257])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>输出的第一个维度是批次的数量（1是因为我们只通过模型运行了一个序列）。第二个维度是序列长度，即输入序列中的标记数量（本例中是7）。第三个维度是词汇量大小。我们为原始序列中的每个标记得到大约5万多个数字的列表。这些是模型的原始输出，或称logits，对应于词表中的标记。对于每个输入标记，模型预测词表中每个标记在该点之后延续序列的可能性。以我们的示例句子为例，模型将为“<code>It</code>”，“<code>It was</code>”，“<code>It was a</code>”等预测logits。较高的logits值意味着模型认为相应的标记更可能是序列的延续。下表显示了输入序列、最可能的标记ID及其对应的标记。</p>
<p>Logits是模型的原始输出（如一串数字[0.1, 0.2, 0.01, …]）。我们可以使用logits来选择最可能延续序列的标记。然而，我们也可以将logits转换为概率，下面会看到。</p>
<table><thead><tr><th>输入序列</th><th>最可能的下一个标记的ID</th><th>对应的token</th></tr></thead><tbody><tr><td>It</td><td>318</td><td>is</td></tr><tr><td>It was</td><td>257</td><td>a</td></tr><tr><td>It was a</td><td>845</td><td>very</td></tr><tr><td>It was a dark</td><td>1755</td><td>night</td></tr><tr><td>It was a dark and</td><td>4692</td><td>cold</td></tr><tr><td>It was a dark and storm</td><td>88</td><td>y</td></tr><tr><td>It was a dark and stormy</td><td>1755</td><td>(let’s figure this one)</td></tr></tbody></table>
<p>我们来关注整个输入句子的logits，并看看如何预测句子的下一个单词。我们可以使用<code>argmax()</code>方法找到具有最高值的标记索引：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">final_logits = gpt2(input_ids).logits[0, -1]  # The last set of logits</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">final_logits.argmax()  # The position of the maximum</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">tensor(1755)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>1755 对应于模型认为最有可能接输入字符串 &quot;<code>It was a dark and stormy</code>&quot; 的标记ID。解码这个标记，我们可以看到这个模型还是清楚一些故事套路的：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.decode(final_logits.argmax())</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&#x27; night&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>所以” night”是最可能的词元。考虑输入的语句，这是讲得通的。模型学会了使用一种叫做自注意力的算法来关注其他词元，这是transformer的基本构件。直观地说，自注意力让模型能识别每个词元对短语含义的贡献有多大。</p>
<blockquote>
<p><strong>注</strong>：transformer模型包含了许多这样的注意力层，每一层都专注于输入的某一方面。与启发式系统相反，这些方面或特征是在训练过程中学习到的，而非事先指定的。</p>
</blockquote>
<p>下面我们通过选择前10个值来看看其他候选词元：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">top10_logits = torch.topk(final_logits, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for index in top10_logits.indices:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(tokenizer.decode(index))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> night</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> day</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> evening</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> morning</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> afternoon</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> summer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> winter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> weekend</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">,</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>需要将logits转换成概率值，以查看模型对每次预测的置信度。我们会通过将每个值与所有其他预测值进行比较，并进行归一化，以使所有数字加起来等于1。这正是<code>softmax()</code>运算的任务。以下代码使用<code>softmax()</code>打印出模型所得可能性最高的前10个词汇及其相关概率：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">top10 = torch.topk(final_logits.softmax(dim=0), 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for value, index in zip(top10.values, top10.indices):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;{tokenizer.decode(index):&lt;10} {value.item():.2%}&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> night     46.18%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> day       23.46%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> evening   5.87%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> morning   4.42%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> afternoon 4.11%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> summer    1.34%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> time      1.33%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> winter    1.22%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> weekend   0.39%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">,          0.38%</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>在做进一步操作之前，建议先用以上代码进行实验。以下是一些建议，供读者尝试：</p>
<p> </p>
<ul>
<li><strong>更改几个单词</strong>：尝试改变输入中的形容词（例如，“<code>dark</code>”和“<code>stormy</code>”），看看模型的预测如何改变。预测的词仍然是“<code>night</code>”吗？概率如何变化？</li>
<li><strong>更改输入内容</strong>：尝试不同的输入字符串，看看模型的预测如何变化。你赞同模型的预测吗？</li>
<li><strong>语法</strong>：如果提供的内容是在语法上不正确的句子会怎么样？模型如何处理？看看顶级预测的概率。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="生成文本">生成文本<a href="#生成文本" class="hash-link" aria-label="生成文本的直接链接" title="生成文本的直接链接">​</a></h3>
<p>一旦知道如何获取模型对序列中下一个词元的预测，通过不断地把模型的预测反馈给它自身，就很容易生成文本了。我们可以调用<code>gpt2(ids)</code>，生成一个新的分词ID，加入到列表中，然后再次调用函数。为了方便生成多个词，transformers自回归模型具有一个合适的方法<code>generate()</code>。下面探讨一个示例。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">output_ids = gpt2.generate(input_ids, max_new_tokens=20)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decoded_text = tokenizer.decode(output_ids[0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Input IDs&quot;, input_ids[0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Output IDs&quot;, output_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f&quot;Generated text: {decoded_text}&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Input IDs tensor([1026,  373,  257, 3223,  290, 6388,   88])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Output IDs tensor([ 1026,   373,   257,  3223,   290,  6388,    88,  1755,    13,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          383,  2344,   373, 19280,    11,   290,   262, 15114,   547,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         7463,    13,   383,  2344,   373, 19280,    11,   290,   262])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Generated text: It was a dark and stormy night. The wind was blowing,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">and the clouds were falling. The wind was blowing, and the</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>在上一节中运行<code>gpt2()</code>的方法时，它返回了词汇表（50257）中每个标记的logits列表。然后，我们需要计算概率并选择最可能的标记。<code>generate()</code>抽象了这个逻辑。它进行多次前向传播，反复预测下一个标记，并将其追加到输入序列中。<code>generate()</code>为我们提供了最终序列的token ID，包括输入和新标记。然后，我们可以用 tokenizer 的<code>decode()</code>方法将其转换回文本。</p>
<p>执行生成有许多种策略。我们刚才选择最大可能性的标记，被称为贪婪解码（greedy decoding）。尽管这种方法直截了当，但有时可能导致次优的结果，特别是在生成较长文本序列时。贪婪解码存在问题，因为它不考虑整个句子的总概率，只关注紧接着的下一个词。例如，给定起始词 <em><code>Sky</code><em>和下一个词的选择 <em><code>blue</code></em> 和 <em><code>rockets</code></em>，贪婪解码可能会偏向 <em><code>Sky blue</code></em>，因为</em><code>blue</code><em>初看 起来更可能紧跟 <em><code>Sky</code></em>。然而，这种方法会忽视更连贯和可能的整体序列，如</em><code>Sky rockets soar</code></em>。因此，贪婪解码有时会错过最可能的整体序列，导致文本生成的效果不理想。</p>
<p>与一次一个token不同，如 Beam Search（束集搜索）这样的技术，会探索序列的多种可能延续，并返回最可能的延续序列。它在生成过程中保持最有可能的 <code>num_beams</code>假设，并选择最有可能的那个。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">beam_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_beams=5,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_new_tokens=30,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(beam_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;It was dark and stormy,&quot; he said.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;It was dark and stormy,&quot; he said.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>可以看到，输出中存在相同序列的多次重复。有一些参数可用于控制执行更好的生成。来看两个例子：</p>
<ul>
<li><code>repetition_penalty</code>：对已生成的词元进行多大程度的惩罚，避免重复。比较好的默 认值是1.2。</li>
<li><code>bad_words_ids</code>：不应生成的词元列表（例如防止生成冒犯性的词汇）。</li>
</ul>
<p>下面看惩罚重复所得到的效果：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">beam_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_beams=5,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repetition_penalty=1.2,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_new_tokens=38,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(beam_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;There was a lot of rain,&quot; he said. &quot;It was very cold.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">He said he saw a man with a gun in his hand.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>效果好很多。该使用哪种生成策略呢？就像机器学习中常说的……这取决于具体情况。当文本的期望长度比较可预测时，束集搜索（beam search）效果较好。它适用于摘要或翻译等任务，但不适用于开放式生成，因为输出长度可能有较大变化，导致重复。尽管我们可以限制模型避免重复，但这样做也可能导致性能下降。还要注意，束集搜索比贪婪搜索（greedy search）要慢，因为它需要同时对多个束进行推理，这对大型模型来说可能是个问题。</p>
<p>在使用贪婪搜索和束集搜索生成文本时，我们提升模型生成高概率的下一个词的分布。有趣的是，高质量的人类语言并不遵循类似的分布。人类文本往往更不可预测。关于这一反直觉现象的优秀论文有《<a href="https://arxiv.org/abs/1904.09751" target="_blank" rel="noopener noreferrer">神经文本退化的奇特案例</a>》。作者推测人类语言不喜欢可预测的词语——人们会避免陈述显而易见的内容。论文提出了一种称为核采样（nucleus sampling）的方法。</p>
<p>采样时，我们通过从下一个词的概率分布中采样来选择下一个词。这意味着采样是一个不确定性的生成过程。如下一个词可能是night（60%）、day（35%）和apple（5%），那么与其选择night（使用贪婪搜索），我们会从分布中采样。换句话说，即使apple是一个低概率的词，有5%的几率被选择，尽管它可能产生不合逻辑的生成内容。采样避免了生成重复文本，因此可以产生更多样化的内容。采样在<em>transformer</em>模型中通过 <code>do_sample</code> 参数来完成。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import set_seed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Setting the seed ensures we get the same results every time we run this code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">set_seed(70)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=34,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=0,  # We&#x27;ll come back to this parameter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy day until it broke down the big canvas on my sleep station, making me money dilapidated, and, with a big soothing mug</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>我们可以在采样之前操控概率分布，通过<code>temperature</code>参数使其变得“更陡峭”或“更平缓”。<code>temperature</code>高于1会增加分布的随机性，这样可以鼓励生成可能性较低的词。<code>temperature</code>在0和1之间会减少随机性，增加可能性较高词的概率，避免过于出乎意料的预测。<code>temperature</code>为0会将所有概率集中到最可能的下一个词，相当于贪婪解码。对比以下示例中<code>temperature</code>参数对生成文本的影响。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature=0.4,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night, and I was alone. I was in the middle of the night, and I was suddenly awakened bygoodness, and I was thinking of the old man</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature=0.001,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night. The wind was blowing, and the clouds were falling. The wind was blowing, and the clouds were falling. The wind was blowing, and the clouds were</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature=3.0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormyfleet verteutorial took possession contingt containing Carol Rhino soils titsfastKEY 07 Deaths od paradeCONT WEEK Barclays Reviskish6 EdwingarPosition serv blat Imperial licenseium Bot</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>第一条测试比第二条连贯得多。第二条测试使用了非常低的temperature，因此文本重复（类似于贪婪解码）。最后，第三个样本temperature极高，生成了无意义的文本。</p>
<p>你可能注意到有一个参数是<code>top_k</code>。是什么呢？Top-K采样是一种简单的采样方法，其中只考虑K个最有可能的后续词。例如，使用<code>top_k=5</code>，生成方法会首先筛选出最有可能的五个词，并重新分配概率使其总和为一。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night and there were some things we didn&#x27;t understand. I didn&#x27;t understand the nature of the problem. I was afraid and scared.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">In response to the</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>嗯……还可以更好。Top-K采样的一个问题是实际中相关候选词的数量可能会有很大差异。如果定义<code>top_k=5</code>，有些分布仍然会包含概率非常低的词，而其他分布则仅包含高概率词。</p>
<p>我们介绍的最后一种生成策略是Top-p采样（也称为核采样）。与采样最高概率的K个词不同，我们使用所有累计概率超过给定值的最可能词。如果我们使用<code>top_p=0.94</code>，首先会筛选出累计概率达到0.94或更高的词，然后重新分配概率并进行常规采样。下面看看实际效果。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_output = gpt2.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_length=40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_p=0.94,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k=0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(sampling_output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">It was a dark and stormy night from 7PM. Tony attended the Rangers game with his boys. He overheard them singing. He recorded a video with Jasper in the booth. He rented an empty</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Top-K和Top-p都是实践中常用的生成方法。它们甚至可以结合起来过滤掉低概率词，同时提供更多的生成控制。使用随机生成方法的问题是生成的文本不一定连贯。</p>
<p>我们已经看到了三种不同的生成方法：贪婪搜索、束集搜索解码和采样（通过temperature、Top-K和Top-p进一步控制）。这类方法很多！如果你想进一步测试生成方法，以下是一些建议：</p>
<ul>
<li>尝试不同的参数值。增加束的数量会如何影响生成质量？减少或增加<code>top_p</code>值会发生什么？</li>
<li>一种减少束集搜索中重复的方法是引入n-gram（n个词的序列）惩罚。可以通过<code>no_repeat_ngram_size</code>配置，避免重复相同的n-gram。例如，使用<code>no_repeat_ngram_size=4</code>，生成的文本就不会包含完全相同的四个连续词。</li>
<li>一种较新的方法，反差搜索，可以生成长且连贯的内容，同时避免重复。这是通过考虑模型预测的概率和上下文的相似性来实现的。可以通过<code>penalty_alpha</code>和<code>top_k</code>控制。有关反差搜索可阅读<a href="https://huggingface.co/blog/introducing-csearch" target="_blank" rel="noopener noreferrer">Generating Human-level Text with Contrastive Search</a>一文。</li>
</ul>
<p>如果这听起来太经验主义，那是因为确实是这么回事。生成式是一个活跃的研究领域，新论文不断提出不同的方案，如更复杂的过滤方法。我们将在最后一章简要讨论这些内容。没有一种方法适用于所有模型，所以对不同的技术做实验很重要。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="零样本泛化">零样本泛化<a href="#零样本泛化" class="hash-link" aria-label="零样本泛化的直接链接" title="零样本泛化的直接链接">​</a></h3>
<p>生成式语言是transformer模型的一个有趣而令人振奋的应用，但<a href="https://openai.com/research/better-language-models" target="_blank" rel="noopener noreferrer">撰写关于独角兽的伪造文章</a>并不是其如此受欢迎的原因。为了很好地预测后一个词，这些模型必须学到相当多的现实世界的知识。我们可以利用这一点来执行各种任务。例如，无需训练一个专门用于翻译的模型，只需用一个足够强大的语言模型来输入一个提示词，像这样：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Translate the following sentence from English to French:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Input: The cat sat on the mat.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Translation:</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>我在GitHub Copilot中实时输入了这一示例，它贴心地建议将“<code>Le chat était assis sur le tapis</code>”作为以上提示词的延续——这是语言模型可以执行未明确训练任务的完美例子。模型越强大，它在无需额外训练的情况下可以执行的任务就越多。这种灵活性使 得transformer模型非常强大，并在近年来变得广受欢迎。</p>
<p>为能亲身体验，我们使用GPT-2作为分类模型。具体来说，我们会对电影评论进行正面或负面的分类——这是NLP领域的经典基准任务。为增加趣味性，我们使用零样本的方式，也就是我们不会向模型提供任何标记数据。而是向模型提供评论文本，让其预测情感。来看看它的表现。</p>
<p>我们将评论插入一个提示词模板，为模型提供上下文，并帮助它理解我们的要求。将提示词输入模型后，查看它对后一个词的预测，看看哪个词概率更高：“<code>positive</code>”还是“<code>negative</code>”？为此，我们需要找出这些词的相应ID。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check the token IDs for the words &#x27; positive&#x27; and &#x27; negative&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># (note the space before the words)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.encode(&quot; positive&quot;), tokenizer.encode(&quot; negative&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">([3967], [4633])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>有了ID之后，就可以使用模型进行推理，查看哪个词具有更高的概率：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def score(review):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Predict whether it is positive or negative</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    This function predicts whether a review is positive or negative</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    using a bit of clever prompting. It looks at the logits for the</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokens &#x27; positive&#x27; and &#x27; negative&#x27; (note the space before the</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    words), and returns the label with the highest score.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    prompt = f&quot;&quot;&quot;Question: Is the following review positive or</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">negative about the movie?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Review: {review} Answer:&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_ids = tokenizer(prompt, return_tensors=&quot;pt&quot;).input_ids  # 对提示词进行分词</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    final_logits = gpt2(input_ids).logits[0, -1]  # 从词汇中获取每个词元的logit，注意我们使用的是gpt2()而不是gpt2.generate()，因为前者返回词中的每个分词的logit，而后者仅返回所选定的分词</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if final_logits[3967] &gt; final_logits[4633]:  # 检测正向分词的logit是否大于负向分词的logit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&quot;Positive&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&quot;Negative&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>可以对几个假评论使用zero-shot分类器进行尝试：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">score(&quot;This movie was terrible!&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Negative</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">score(&quot;That was a delight to watch, 10/10 would recommend :)&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Positive</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">score(&quot;A complex yet wonderful film about the depravity of man&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Positive</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>在补充材料中，有一个已打标记的评论数据集和用于评估这种零样本方法准确性的代码。尝试调整提示词模板以提高模型的性能。看看还能想到其他可以使用类似方法执行的任务吗？</p>
<p>最近模型的零样本能力大大改变了游戏规则。随着模型的改进，它们可以开箱即用地执行更多任务，使其更易于使用，并减少了每个任务需要专用模型的需求。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="少样本泛化">少样本泛化<a href="#少样本泛化" class="hash-link" aria-label="少样本泛化的直接链接" title="少样本泛化的直接链接">​</a></h3>
<p>虽然有先进的ChatGPT以及对外界完美提示词的追求，零样本泛化（或提示词调优）并不是让强大的语言模型执行各类任务的唯一路径。</p>
<p>零样本泛化是少样本（<em>few-shot</em> ）泛化技术的极端应用，在少样本泛化中，我们向语言模型提供一些希望它 执行的任务的示例，然后让其提供类似的答案。我们不是在训练模型，而是通过展示一些示例来影响生成的内容，增加生成文本遵循我们的提示词结构和模式的概率。</p>
<p>来看一个例子。提供示例之外，提供一段简短的描述，例如“<code>Translate English to French</code>”，也有助于生成更高质量的内容。这次，我们使用一个更强大的模型：<a href="https://huggingface.co/EleutherAI/gpt-neo-1.3B" target="_blank" rel="noopener noreferrer">GPT-Neo 1.3B</a>。GPT-Neo是由非营利研究实验室EleutherAI开发的一系列transformer模型。这些模型在许多任务中表现优于GPT-2，并且在少样本学习方面表现更好。我们使用13亿参数的变体，虽然在今天看来不算大，但它依然相当强大，是GPT-2（仅有1.24亿参数）的十倍。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModelForCausalLM.from_pretrained(&quot;EleutherAI/gpt-neo-1.3B&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">prompt = &quot;&quot;&quot;\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Translate English to Spanish:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: I do not speak Spanish.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: No hablo español.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: See you later!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¡Hasta luego!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: Where is a good restaurant?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¿Dónde hay un buen restaurante?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: What rooms do you have available?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¿Qué habitaciones tiene disponibles?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: I like soccer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish:&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).input_ids</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output = model.generate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    do_sample=False,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_new_tokens=10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(tokenizer.decode(output[0], skip_special_tokens=True))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Translate English to Spanish:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: I do not speak Spanish.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: No hablo español.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: See you later!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¡Hasta luego!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: Where is a good restaurant?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¿Dónde hay un buen restaurante?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: What rooms do you have available?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: ¿Qué habitaciones tiene disponibles?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">English: I like soccer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish: Me gusta el fútbol</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>我们描述了要实现的任务，并提供了四个示例设置模型的上下文。因此，这是一个4-shot泛化任务。然后，我们要求模型生成更多文本以遵循模式并提供所需的翻译。以下是一些可以探索的想法：</p>
<ul>
<li>更少的示例是否可以？</li>
<li>没有任务描述是否可行？</li>
<li>其他任务如何？</li>
<li>在这一情况下，GPT-2的表现如何？</li>
</ul>
<blockquote>
<p><strong>注：</strong> 由于GPT-2的大小和训练过程，它在少样本任务上表现不是很好，在零样本泛化上甚至更差。我们如何在之前的例子中使用它进行情感分类呢？其实做了一点小手脚：我们没有查看模型生成的文本，只是检查了“Positive”的概率是否大于“Negative”的概率。理解模型的底层工作原理，即使是小模型，也能解锁强大的应用。要思考你的问题，不要害怕探索。</p>
</blockquote>
<p>GPT-2是一个基础模型的例子。以GPT-2为风格的一些底座模型具有在推理时使用的零样本和少样本能力。另一种方式是模型微调：我们在基础模型之上继续在特定的领域或任务数据上训练。通常很少需要世界上最强大的模型展示的极端泛化能力；如果只要解决一个特定任务，更便宜且更好的是微调并部署一个专门用于单一任务的小模型。同样重要的是要注意基础模型不是对话式的；尽管可以编写一个非常好的提示词来使用基础模型创建一个聊天机器人，但通常更方便的是使用对话数据微调基础模型，从而提高模型的对话能力。在第五章中会进行实践。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="transformer解构">Transformer解构<a href="#transformer解构" class="hash-link" aria-label="Transformer解构的直接链接" title="Transformer解构的直接链接">​</a></h2>
<p>在简单实践语言模型之后，我们准备介绍基于transformer的语言生成模型的架构图。涉及到的高阶组件有：</p>
<ul>
<li>
<p><strong>分词</strong>：输入文本被分解为单个<em>token</em>（可以是单词和子词）。每个词元都有一个对应的ID，用于索引词嵌入。</p>
</li>
<li>
<p><strong>输入词嵌入</strong>：token以称为嵌入的向量进行表示。这些嵌入为数值形式，捕获每个token的语义。可以将向量视为数字列表，每个数字对应token含义的特定方面。在训练过程中，模型学习如何将每个token映射到对应的嵌入。无论token在输入序列中的位置如何，嵌入总是相同的。</p>
</li>
<li>
<p><strong>位置编码</strong>：transformer模型没有顺序的概念，因此我们需要用位置信息丰富词嵌入。通过将位置编码添加到词嵌入中来实现。位置编码是一组向量，编码了输入序列中每个token的位置。使得模型能够根据序列中的位置区分标记，这很有用，因为同一个token出现在不同位置可以有不同的含义。</p>
</li>
<li>
<p><strong>Transformer块</strong>：transformer模型的核心是transformer块。transformer的强大之处在于堆叠多个块，使模型能够学习输入token之间越来越复杂和抽象的关系。它由两个主要组件组成：</p>
<ul>
<li><strong>自注意义力机制</strong>：这种机制允许模型在整个序列的上下文中权衡每个token的  重要性。它帮助模型理解输入中不同token之间的关系。自注意力机制是transformer处理长程依赖和复杂词语关系的关键，可生成连贯且语境恰当的文本。</li>
<li><strong>前馈神经网络</strong>：自注意力输出通过前馈神经网络进一步细化输入序列的表示。</li>
</ul>
</li>
<li>
<p><strong>上下文嵌入</strong>：transformer块的输出是一组上下文嵌入，捕获输入序列中token之间的关系。与每个token固定的输入嵌入不同，上下文嵌入在transformer模型的每一层中根据token之间的关系进行更新。</p>
</li>
<li>
<p><strong>预测</strong>：一个额外的层将最终表示处理为任务相关的最终输出。对于文本生成，这涉及一个线性层将上下文嵌入映射到词空间，随后进行softmax运算以预测序列中的下一个token。</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://i.taixr.com/2024060611015857.png" alt="图2-1：基于transformer的模型的架构" class="img_ev3q"></p>
<p><strong>图2-1：</strong> 基于transformer的模型的架构</p>
<p>当然，这只是对transformer架构的简化描述。深入研究自注意力机制的工作原理或transformer块的内部机制暂不在我们的讨论范围。但理解transformer模型的顶层架构有助于掌握这些模型的工作原理以及将其应用于各种任务。这种架构使transformer在各种任务和领域中取得了前所未有的表现，你会发现它们不断出现——不仅是在本系列文章，而是在整个学科中。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="transformer模型家族">Transformer模型家族<a href="#transformer模型家族" class="hash-link" aria-label="Transformer模型家族的直接链接" title="Transformer模型家族的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="序列到序列的任务">序列到序列的任务<a href="#序列到序列的任务" class="hash-link" aria-label="序列到序列的任务的直接链接" title="序列到序列的任务的直接链接">​</a></h3>
<p>在本章的开头，我们使用GPT-2进行了自回归文本生成实验。GPT-2是基于解码器的transformer示例，它具有一组transformer块，用于处理输入序列。这是当今流行的方式，但原始的transformer论文《<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need</a>》中使用了一种更复杂的架构，称为编码器-解码器架构，这种架构至今仍在广泛使用。</p>
<p><img decoding="async" loading="lazy" src="https://i.taixr.com/2023041405113684.webp" alt="机器学习 Transformer" class="img_ev3q"></p>
<p>transformer论文专注于机器翻译这一序列到序列的任务。当时，机器翻译的最佳结果是通过循环神经网络（RNN）实现的，例如LSTM和GRU（读者如果不熟悉，不必担心）。该论文通过专注于注意力方法展示了更好的结果，并表达了其可扩展性和训练更容易。这些因素——出色的表现、稳定的训练和易于扩展——是transformer取得成功并被应用于多种任务的原因，下一节将更深入地探讨这些方面。</p>
<p>在编码器-解码器模型中，就像论文中描述的原始transformer模型，一组transformer块（称为编码器）将输入序列处理成一组丰富的表示，然后将其传递给另一组transformer块（称为解码器），解码它们为输出序列。这种将一个序列转换为另一个序列的方法称为序列到序列或seq2seq，适用于翻译、摘要或问答等任务。</p>
<p>例如，将一段英文句子喂给翻译模型的编码器，生成一个捕获输入含义的嵌入。然后，解码器使用这个嵌入生成对应的法语句子。生成过程在解码器中按token逐一进行，在本章早些时候生成序列时有演示。然而，对每个后续token的预测不仅受到正在生成的序列中前一个token的影响，还受到来自编码器的输出的 影响。</p>
<p>将编码器端的输出合并到解码器堆栈中的机制称为交叉注意力。它类似于自注意力，不同之处在于输入中的每个token（解码器正在处理的序列）关注的是来自编码器的上下文，而不是其序列中的其他token。交叉注意力层与自注意力交错，让解码器能够使用其序列中的上下文和来自编码器的信息。</p>
<p>在transformer论文发表后，现有的序列到序列模型，如Marian NMT，将这些技术作为其架构的核心部分进行了整合。使用这些思想开发了新的模型。其中一个值得关注的是BART（“<code>Bidirectional and Auto-Regressive Transformers</code>”的缩写）。在预训练期间，BART会破坏输入序列，并尝试在解码器输出中重建。之后，BART会针对其他生成任务（如翻译或摘要）进行微调，利用预训练期间获得的丰富序列表示。顺便说一下，输入破坏是扩散模型背后的关键思想之一，我们将在第三章中讲到。</p>
<p>另一个值得注意的序列到序列模型是<a href="http://arxiv.org/abs/1910.10683" target="_blank" rel="noopener noreferrer">T5</a>。T5以通用的方式处理多种NLP任务，通过将60种任务表述为文本到文本的转换。不同任务不需要自定义层或代码，训练使用相同的超参数，模型从多样化的数据集中学习。</p>
<p>我们刚刚讨论了编码器-解码器和单解码器架构。常见的问题是，为什么像翻译这样的任务需要编码器-解码器模型，而诸如GPT-2的单解码器模型也能表现良好的结果。编码器-解码器模型旨在将整个输入序列翻译为输出序列，使其极其适合翻译任务。而单解码器模型专注于预测序列中的下一个token。最初，像GPT-2这样的单解码器模型在零样本学习场景中的能力不如更先进的模型如GPT-3，但这不仅仅是因为缺少编码器。像GPT-3这样的高级模型在零样本能力上的提升源自更大的训练 数据、改进的训练技术和更大的模型规模。尽管seq2seq模型中的编码器在理解输入序列的完整上下文中发挥着关键作用，但单解码器模型的进步使它们更加有效和多样化，即使对于传统上依赖seq2seq模型的任务也是如此。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/taixr/portal/tree/main/docs/generative-ai/transformers.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/generative-ai/intro"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">第一章 多媒体生成入门</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/generative-ai/diffusion-models"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">第三章 扩散模型</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#实操语言模型" class="table-of-contents__link toc-highlight">实操语言模型</a><ul><li><a href="#文本分词" class="table-of-contents__link toc-highlight">文本分词</a></li><li><a href="#预测概率" class="table-of-contents__link toc-highlight">预测概率</a></li><li><a href="#生成文本" class="table-of-contents__link toc-highlight">生成文本</a></li><li><a href="#零样本泛化" class="table-of-contents__link toc-highlight">零样本泛化</a></li><li><a href="#少样本泛化" class="table-of-contents__link toc-highlight">少样本泛化</a></li></ul></li><li><a href="#transformer解构" class="table-of-contents__link toc-highlight">Transformer解构</a></li><li><a href="#transformer模型家族" class="table-of-contents__link toc-highlight">Transformer模型家族</a><ul><li><a href="#序列到序列的任务" class="table-of-contents__link toc-highlight">序列到序列的任务</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/category/learn-javascript-with-p5js">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.facebook.com/taixr" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.tiktok.com/@taixr" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/1536802703" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/taixr/portal" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Taixr</div></div></div></footer></div>
</body>
</html>